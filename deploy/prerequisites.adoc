---
permalink: deploy/prerequisites.html 
sidebar: sidebar 
keywords: ONTAP tools,Storage Replication Adapter 
summary: Vor der Bereitstellung der ONTAP Tools für VMware vSphere sollten Sie mit den Speicherplatzanforderungen für das Deployment-Paket und einigen grundlegenden Anforderungen an das Host-System vertraut sein. 
---
= ONTAP-Tools für VMware vSphere – Anforderungen und Konfigurationsgrenzen
:allow-uri-read: 
:icons: font
:imagesdir: ../media/


[role="lead"]
Vor der Bereitstellung der ONTAP Tools für VMware vSphere sollten Sie mit den Speicherplatzanforderungen für das Deployment-Paket und einigen grundlegenden Anforderungen an das Host-System vertraut sein.

Sie können ONTAP-Tools für VMware vSphere mit der virtuellen VMware vCenter Server-Appliance (vCSA) verwenden. Sie sollten ONTAP-Tools für VMware vSphere auf einem unterstützten vSphere-Client mit ESXi-System implementieren.



== Systemanforderungen

* *Platzanforderungen für Installationspaket pro Knoten*
+
** 15 GB bei Thin Provisioning-Installationen
** 348 GB für Thick Provisioning-Installationen


* *Anforderungen an die Dimensionierung des Hostsystems* Die folgende Tabelle zeigt den empfohlenen Arbeitsspeicher für jede Bereitstellungsgröße. Für Bereitstellungen mit hoher Verfügbarkeit (HA) benötigen Sie die dreifache Appliance-Größe, die angegeben ist.


|===


| *Art der Bereitstellung* | *CPUs pro Knoten* | *Arbeitsspeicher (GB) pro Node* | *Speicherplatz (GB) Thick Provisioning pro Knoten* 


| Klein | 9 | 18 | 350 


| Mittel | 13 | 26 | 350 


| HINWEIS: Bei der großen Implementierung geht es nur um die HA-Konfiguration. | 17 | 34 | 350 
|===

NOTE: Wenn Backup aktiviert ist, benötigt jeder Cluster mit ONTAP Tools weitere 50 GB Speicherplatz auf dem Datenspeicher, auf dem die VMs implementiert werden. Daher sind für nicht-HA 400 GB und für HA insgesamt 1100 GB Speicherplatz erforderlich.



== Mindestanforderungen hinsichtlich Storage und Applikationen

|===
| Storage, Host und Applikationen | Versionsanforderungen 


| ONTAP | 9.15.1, 9.16.0, 9.16.1, 9.17.0 und 9.17.1 


| Von ONTAP Tools unterstützte ESXi-Hosts | Ab 7.0.3 


| ONTAP Tools unterstützten vCenter Server | 7.0U3 ab 


| VASA Provider | 3.0 


| OVA-Anwendung | 10,5 


| ESXi-Host zur Implementierung der virtuellen Maschine mit ONTAP-Tools | 7.0U3 und 8.0U3 


| VCenter Server zur Bereitstellung einer virtuellen Maschine mit ONTAP-Tools | 7.0 und 8.0 
|===

NOTE: Ab ONTAP-Tools für VMware vSphere 10.4 wird die Hardware der virtuellen Maschine von Version 10 auf 17 geändert.

Das Interoperabilitäts-Matrix-Tool (IMT) enthält aktuelle Informationen zu den unterstützten Versionen von ONTAP, vCenter Server, ESXi-Hosts und Plug-in-Applikationen.

https://imt.netapp.com/matrix/imt.jsp?components=105475;&solution=1777&isHWU&src=IMT["Interoperabilitäts-Matrix-Tool"^]



== Port-Anforderungen

Die folgende Tabelle zeigt die von NetApp verwendeten Netzwerkports und deren Zweck. Es gibt drei verschiedene Arten von Anschlüssen:

* Externe Ports: Diese Ports sind von außerhalb des Kubernetes-Clusters oder -Knotens zugänglich. Sie ermöglichen es Diensten, mit externen Netzwerken oder Benutzern zu kommunizieren und so die Integration mit Systemen außerhalb der Clusterumgebung zu ermöglichen.
* Inter-Node-Ports: Diese Ports ermöglichen die Kommunikation zwischen den Knoten innerhalb des Kubernetes-Clusters. Sie werden für Clusteraufgaben wie den Datenaustausch und die Zusammenarbeit benötigt. Bei Einzelknoten-Bereitstellungen werden die Inter-Node-Ports nur innerhalb des Knotens verwendet und benötigen keinen externen Zugriff. Inter-Node-Ports können Datenverkehr von außerhalb des Clusters akzeptieren. Sperren Sie den Internetzugang zwischen den Knoten mithilfe von Firewall-Regeln.
* Interne Ports: Diese Ports kommunizieren innerhalb des Kubernetes-Clusters über ClusterIP-Adressen. Sie sind nicht extern zugänglich und müssen nicht zu Firewall-Regeln hinzugefügt werden.



NOTE: Stellen Sie sicher, dass sich alle ONTAP Tool-Knoten im selben Subnetz befinden, um eine unterbrechungsfreie Kommunikation untereinander aufrechtzuerhalten.


|===
| *Dienst-/Komponentenname* | *Port* | *Protokoll* | *Anschlusstyp* | *Beschreibung* 


| ntv-gateway-svc (LB) | 443, 8443 | TCP | Extern | Durchgangsport für eingehende Kommunikation für den VASA-Provider-Dienst. Auf diesem Port werden das selbstsignierte Zertifikat des VASA-Anbieters und das benutzerdefinierte CA-Zertifikat gehostet. 


| SSH | 22 | TCP | Extern | Secure Shell für die Anmeldung am Remote-Server und die Ausführung von Befehlen. 


| rke2-Server | 9345 | TCP | Zwischenknoten | RKE2 Supervisor API (Beschränkung auf vertrauenswürdige Netzwerke). 


| kube-apiserver | 6443 | TCP | Zwischenknoten | Kubernetes API-Server-Port (auf vertrauenswürdige Netzwerke beschränken). 


| rpcbind/portmapper | 111 | TCP/UDP | Zwischenknoten | Wird für die RPC-Kommunikation zwischen Diensten verwendet. 


| coredns (DNS) | 53 | TCP/UDP | Zwischenknoten | Domain Name System (DNS)-Dienst zur Namensauflösung innerhalb des Clusters. 


| NTP | 123 | UDP | Zwischenknoten | Netzwerkzeitprotokoll (NTP) zur Zeitsynchronisation. 


| etcd | 2379, 2380, 2381 | TCP | Zwischenknoten | Schlüsselwertspeicher für Clusterdaten. 


| kube-vip | 2112 | TCP | Zwischenknoten | Kubernetes API-Server-Port. 


| kubelet | 10248, 10250 | TCP | Zwischenknoten | Kubernetes-Komponente 


| kube-controller | 10257 | TCP | Zwischenknoten | Kubernetes-Komponente 


| Cloud-Controller | 10258 | TCP | Zwischenknoten | Kubernetes-Komponente 


| kube-scheduler | 10259 | TCP | Zwischenknoten | Kubernetes-Komponente 


| kube-proxy | 10249, 10256 | TCP | Zwischenknoten | Kubernetes-Komponente 


| Kaliko-Knoten | 9091, 9099 | TCP | Zwischenknoten | Calico-Netzwerkkomponente. 


| containerd | 10010 | TCP | Zwischenknoten | Container-Daemon-Dienst. 


| VXLAN (Flannel) | 8472 | UDP | Zwischenknoten | Overlay-Netzwerk für die Pod-Kommunikation. 
|===

NOTE: Bei HA-Bereitstellungen muss sichergestellt werden, dass der UDP-Port 8472 zwischen allen Knoten geöffnet ist. Dieser Port ermöglicht die Kommunikation zwischen Pods über verschiedene Knoten hinweg; durch Blockierung wird die Netzwerkverbindung zwischen den Knoten unterbrochen.



== Konfigurationsbeschränkungen für die Implementierung von ONTAP Tools für VMware vSphere

Die folgende Tabelle bietet einen Leitfaden zur Konfiguration von ONTAP Tools für VMware vSphere.

|===


| * Bereitstellung* | *Typ* | *Anzahl der VVols* | *Anzahl der Hosts* 


| Ohne HA | Klein (S) | ~12.000 | 32 


| Ohne HA | Mittel (M) | ~24.000 | 64 


| Hochverfügbarkeit | Klein (S) | ~24.000 | 64 


| Hochverfügbarkeit | Mittel (M) | ~50.000 | 128 


| Hochverfügbarkeit | Groß (L) | 100 ~ | 256 [HINWEIS] Die Hostanzahl in der Tabelle stellt die Gesamtzahl aller verbundenen vCenter dar. 
|===


== ONTAP Tools für VMware vSphere – Storage Replication Adapter (SRA)

In der folgenden Tabelle sind die Zahlen aufgeführt, die pro VMware Live Site Recovery-Instanz mithilfe von ONTAP Tools für VMware vSphere unterstützt werden.

|===
| *VCenter-Bereitstellungsgröße* | *Klein* | *Mittel* 


| Gesamtzahl der virtuellen Maschinen, die für den Schutz mithilfe einer Array-basierten Replikation konfiguriert wurden | 2000 | 5000 


| Gesamtzahl der Array-basierten Replikationsschutzgruppen | 250 | 250 


| Gesamtzahl der Schutzgruppen pro Wiederherstellungsplan | 50 | 50 


| Anzahl replizierter Datastores | 255 | 255 


| Anzahl der VMs | 4000 | 7000 
|===
In der folgenden Tabelle sind die Anzahl der VMware Live Site Recovery und die entsprechenden ONTAP Tools für die VMware vSphere Implementierungsgröße aufgeführt.

|===


| *Anzahl der VMware Live Site Recovery Instanzen* | *Größe der Bereitstellung von ONTAP-Tools* 


| Bis Zu 4 | Klein 


| 4 bis 8 | Mittel 


| Mehr als 8 | Groß 
|===
Weitere Informationen finden Sie unter https://techdocs.broadcom.com/us/en/vmware-cis/live-recovery/live-site-recovery/9-0/overview/site-recovery-manager-system-requirements/operational-limits-of-site-recovery-manager.html["Betriebsgrenzen der VMware Live Site Recovery"].
